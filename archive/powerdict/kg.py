# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/08-knowledge-graph.ipynb (unless otherwise specified).

__all__ = [
    'load_entity_data',
    'get_entity_url',
    'load_raw_triplets_df',
    'load_build_data',
    'aggregate_triplets',
    'extract_entity_attribute_triplets',
    'extract_cleaned_triplets',
    'construct_knowledge_graph_triplets',
]

# Cell
import json
import yaml
import numpy as np
import pandas as pd

# Cell
def load_entity_data(entity_data_fp: str = 'data/intermediate/site_data.json'):
    with open(entity_data_fp, 'r') as f:
        entity_data = json.load(f)

    return entity_data


# Cell
get_entity_url = (
    lambda entity_id, endpoint='https://osuked.github.io/Power-Station-Dictionary/objects': f'{endpoint}/{entity_id}'
)

# Cell
def load_raw_triplets_df(entity_data: dict):
    triplet_data = []
    columns = ['subject', 'predicate', 'object', 'source']

    for entity_id, data in entity_data.items():
        if 'attributes' in data.keys():
            for attr in data['attributes']:
                if 'rdfType' in attr['field_schema'].keys():
                    triplet_data += [
                        [get_entity_url(entity_id), attr['field_schema']['rdfType'], attr['value'], attr['source']]
                    ]

    df_triplets = pd.DataFrame(triplet_data, columns=columns)

    return df_triplets


# Cell
def load_build_data(build_data_fp: str = 'data/dictionary/build.yml'):
    with open(build_data_fp, 'r') as f:
        build_data = yaml.safe_load(f)

    return build_data


# Cell
def aggregate_triplets(
    df_triplets: pd.DataFrame, aggregation: bool = None, math_agg_options: list = ['mean', 'max', 'min', 'sum', 'std']
):
    ## this needs to be able to properly handle the edge-case where there are
    ## multiple different values from the same dataset and aggregation=None

    assert aggregation != True, '`aggregation` can not be `True`'
    df_triplets = df_triplets.drop_duplicates()

    if aggregation == False:
        agg_triplets = list(df_triplets[['subject', 'predicate', 'object']].to_records(index=False))

    elif aggregation in math_agg_options:
        multi_idx = pd.MultiIndex.from_arrays(df_triplets[['subject', 'predicate']].to_numpy().T)

        df_triplets_agg = getattr(df_triplets['object'].groupby(multi_idx), aggregation)().reset_index()
        df_triplets_agg['subject'] = df_triplets_agg['index'].str[0]
        df_triplets_agg['predicate'] = df_triplets_agg['index'].str[1]

        agg_triplets = list(
            df_triplets_agg.drop(columns=['index'])[['subject', 'predicate', 'object']].to_records(index=False)
        )

    else:
        if df_triplets.shape[0] <= 1:
            agg_triplets = list(df_triplets[['subject', 'predicate', 'object']].to_records(index=False))
        else:
            raise ValueError(f'`{aggregation}` is not recognised as a valid value for `aggregation`')

    return agg_triplets


def extract_entity_attribute_triplets(
    entity_url, entity_attribute, source_priority_list, df_triplets, aggregation=None
):
    entity_attribute_triplets = []
    df_triplets_entity_attribute = df_triplets.query('subject==@entity_url & predicate==@entity_attribute')

    for source in source_priority_list:
        df_triplets_entity_attribute_source = df_triplets_entity_attribute.query('source==@source')
        if df_triplets_entity_attribute_source.shape[0] > 0:
            entity_attribute_triplets += aggregate_triplets(
                df_triplets_entity_attribute_source, aggregation=aggregation
            )

    return entity_attribute_triplets


def extract_cleaned_triplets(df_triplets: pd.DataFrame, build_data: dict):
    cleaned_triplets = []

    for entity_url in sorted(df_triplets['subject'].unique()):
        for entity_attribute in build_data['entity_attributes'].keys():
            source_priority_list = build_data['entity_attributes'][entity_attribute]['priority']

            if 'aggregation' in build_data['entity_attributes'][entity_attribute].keys():
                aggregation = build_data['entity_attributes'][entity_attribute]['aggregation']
            else:
                aggregation = None

            cleaned_triplets += extract_entity_attribute_triplets(
                entity_url, entity_attribute, source_priority_list, df_triplets, aggregation
            )

    return cleaned_triplets


# Cell
def construct_knowledge_graph_triplets(
    entity_data: dict,
    build_data_fp: str = 'data/dictionary/build.yml',
    cleaned_triplets_fp: str = 'data/knowledge_graph/triplets.json',
):
    build_data = load_build_data(build_data_fp)
    df_triplets = load_raw_triplets_df(entity_data)
    cleaned_triplets = extract_cleaned_triplets(df_triplets, build_data)

    with open(cleaned_triplets_fp, 'w') as f:
        json.dump([list(triplet) for triplet in cleaned_triplets], f)
