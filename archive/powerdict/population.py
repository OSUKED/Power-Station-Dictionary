# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/03-page-population.ipynb (unless otherwise specified).

__all__ = [
    'get_dp_field_to_url_format_str',
    'get_dp_field_to_title',
    'format_id_values',
    'single_site_data_to_ids_df',
    'single_site_data_to_ids_md_str',
    'get_datapackage_url_to_alt_indexes',
    'get_datapackage_url_to_attributes',
    'filter_dict',
    'set_multi_index_names',
    'create_multi_index_attrs_df',
    'get_attrs_df_index_cols',
    'create_single_index_attrs_df',
    'idx_to_attr_name',
    'get_field_class',
    'format_attribute_value_types',
    'construct_attr_to_field_schema',
    'extract_datapackage_url_to_ids',
    'extract_combined_attrs_df',
    'extract_datapackage_url_to_dict_id_type',
    'get_datapackage_url_to_attrs_md_str',
    'construct_dataset_md_str',
    'single_site_data_to_datasets_md_str',
    'clean_dp_name',
    'construct_downloads_md_str',
    'construct_contributors_str',
    'extract_name_from_single_site_data',
    'single_site_data_to_md_str',
    'populate_and_save_template',
    'clean_object_ids_to_names',
    'get_object_ids_to_names',
    'construct_object_docs',
]

# Cell
import json
import numpy as np
import pandas as pd
from frictionless import Package

from powerdict import extraction

import os
from tqdm import tqdm
from warnings import warn

from jinja2 import Template

# Cell
def get_dp_field_to_url_format_str(datapackage_json_fp):
    package = Package(datapackage_json_fp, profile='tabular-data-package')
    ids_resource = package.get_resource('ids')

    id_field_to_url_format_str = {
        field['name']: field['url_format'] for field in ids_resource['schema']['fields'] if 'url_format' in field.keys()
    }

    return id_field_to_url_format_str


# Cell
def get_dp_field_to_title(datapackage_json_fp):
    package = Package(datapackage_json_fp, profile='tabular-data-package')
    ids_resource = package.get_resource('ids')

    id_field_to_title = {field['name']: field['title'] for field in ids_resource['schema']['fields']}

    return id_field_to_title


# Cell
def format_id_values(id_values, id_type, id_field_to_url_format_str):
    if id_type in id_field_to_url_format_str.keys():
        url_format_str = id_field_to_url_format_str[id_type]
        id_values_strs = [f'[{id_value}]({url_format_str.format(value=id_value)})' for id_value in id_values]
    else:
        id_values_strs = [str(id_value) for id_value in id_values]

    return id_values_strs


# Cell
def single_site_data_to_ids_df(single_site_data, root_id, datapackage_json_fp, root_id_type='dictionary_id'):
    id_field_to_url_format_str = get_dp_field_to_url_format_str(datapackage_json_fp)
    id_field_to_title = get_dp_field_to_title(datapackage_json_fp)

    df_site_ids = pd.DataFrame([{'Relationship': 'Root', 'ID Type': id_field_to_title[root_id_type], 'ID(s)': root_id}])

    hierarchy_level_to_relationship = {'parent': 'parent', 'child': 'Related', 'equivalent': 'Equivalent'}

    for hierarchy_level, ids in single_site_data['id_hierarchies'].items():
        if len(ids) >= 1:
            ids = {
                id_field_to_title[id_type]: (
                    ', '.join([str(id_) for id_ in format_id_values(id_values, id_type, id_field_to_url_format_str)])
                    if isinstance(id_values, list)
                    else f'[{id_values}]({id_field_to_url_format_str[id_type].format(value=id_values)})'
                    if id_type in id_field_to_url_format_str.keys()
                    else id_values
                )
                for id_type, id_values in ids.items()
            }

            relationship = hierarchy_level_to_relationship[hierarchy_level]

            df_site_ids = df_site_ids.append(
                pd.Series(ids)
                .reset_index()
                .assign(Relationship=relationship)
                .rename(columns={'index': 'ID Type', 0: 'ID(s)'})
            )

    if df_site_ids.size >= 1:
        df_site_ids = df_site_ids.set_index(['Relationship', 'ID Type'])

    return df_site_ids


def single_site_data_to_ids_md_str(single_site_data, root_id, datapackage_json_fp):
    df_site_ids = single_site_data_to_ids_df(single_site_data, root_id, datapackage_json_fp)
    site_ids_md_table = df_site_ids.reset_index().to_markdown(index=False)
    site_ids_md_str = '### Identifiers\n\n' + site_ids_md_table

    return site_ids_md_str


# Cell
filter_dict = lambda dict_, keys_to_select: {k: dict_[k] for k in keys_to_select}


def get_datapackage_url_to_alt_indexes(single_site_data):
    datapackage_url_to_alt_indexes = {}

    if 'datasets' in single_site_data.keys():
        for datapackage_url, dataset_ref in single_site_data['datasets'].items():
            alt_indexes = []

            if 'alt_indexes' in dataset_ref['related_resources'][0].keys():
                alt_indexes += dataset_ref['related_resources'][0]['alt_indexes']

            datapackage_url_to_alt_indexes[datapackage_url] = alt_indexes

    return datapackage_url_to_alt_indexes


def get_datapackage_url_to_attributes(single_site_data):
    datapackage_url_to_attributes = {}

    if 'attributes' in single_site_data.keys():
        for attr in single_site_data['attributes']:
            datapackage_url = attr['source']
            attribute_values = filter_dict(attr, ['attribute', 'value', 'id'])

            if datapackage_url not in datapackage_url_to_attributes.keys():
                datapackage_url_to_attributes[datapackage_url] = []

            datapackage_url_to_attributes[datapackage_url] += [attribute_values]

    return datapackage_url_to_attributes


# Cell
get_attrs_df_index_cols = lambda df_attrs: ['attribute'] + [
    elem for elem in df_attrs.columns if elem not in ('attribute', 'id', 0)
]


def set_multi_index_names(df, names, capitalise=True):
    if capitalise == True:
        names = [name.capitalize() for name in names]

    df.index.names = names

    return df


def create_multi_index_attrs_df(attributes, alt_indexes):
    df_attrs = (
        pd.DataFrame(attributes)
        .set_index(['attribute', 'id'])['value']
        .apply(pd.Series)
        .drop_duplicates()
        .stack()
        .reset_index()
        .pipe(lambda df: df.pivot(get_attrs_df_index_cols(df), 'id', 0))
        .pipe(set_multi_index_names, ['attribute'] + alt_indexes)
    )

    attr_ids = list(df_attrs.columns)

    if df_attrs.shape[1] == 1:
        df_attrs.columns.name = ''
        df_attrs.columns = ['value']

    return df_attrs, attr_ids


# Cell
def create_single_index_attrs_df(attributes):
    df_attrs = pd.DataFrame(attributes)
    attr_ids = list(df_attrs['id'].unique())

    if len(attr_ids) > 1:
        df_attrs = df_attrs.pivot('attribute', 'id', 'value')
    else:
        df_attrs = df_attrs.set_index('attribute').drop(columns='id')
        df_attrs = df_attrs.rename(columns={'value': 'Value'})

    return df_attrs, attr_ids


# Cell
from frictionless.types.array import type_to_class
from frictionless.field import Field

construct_attr_to_field_schema = lambda single_site_data: {
    attr['attribute']: attr['field_schema'] for attr in single_site_data['attributes']
}


def idx_to_attr_name(idx):
    if isinstance(idx, tuple):
        attr = idx[0]
    else:
        attr = idx

    return attr


def get_field_class(attr, attr_to_field_schema):
    assert (
        attr in attr_to_field_schema.keys()
    ), f'`{attr}` was not one of the keys provided: {", ".join(attr_to_field_schema.keys())}'
    field_schema = Field(attr_to_field_schema[attr])
    field_type = field_schema['type']
    field_class = type_to_class[field_type](field_schema)

    return field_class


def format_attribute_value_types(df_attributes, attr_to_field_schema):
    for idx, row in df_attributes.iterrows():
        attr = idx_to_attr_name(idx)

        if attr in attr_to_field_schema.keys():
            field_class = get_field_class(attr, attr_to_field_schema)

            for id_, value in row.items():
                df_attributes.loc[idx, id_] = field_class.read_cell(value)

    return df_attributes


# Cell
extract_datapackage_url_to_dict_id_type = lambda single_site_data: {
    k: v['related_resources'][0]['dictionary_pk_field'] for k, v in single_site_data['datasets'].items()
}


def extract_datapackage_url_to_ids(single_site_data):
    assert 'attributes' in single_site_data.keys(), '`single_site_data` must contain an attributes key'
    datapackage_url_to_ids = {}

    for attr in single_site_data['attributes']:
        datapackage_url = attr['source']

        if datapackage_url not in datapackage_url_to_ids.keys():
            datapackage_url_to_ids[datapackage_url] = []

        datapackage_url_to_ids[datapackage_url] += [attr['id']]

    return datapackage_url_to_ids


def extract_combined_attrs_df(single_site_data, attr_to_field_schema):
    datapackage_url_to_alt_indexes = get_datapackage_url_to_alt_indexes(single_site_data)
    datapackage_url_to_dict_id_type = extract_datapackage_url_to_dict_id_type(single_site_data)

    df_combined_attrs = pd.DataFrame()

    for datapackage_url, attrs in get_datapackage_url_to_attributes(single_site_data).items():
        alt_indexes = datapackage_url_to_alt_indexes[datapackage_url]

        if len(alt_indexes) > 0:
            df_attrs, attr_ids = create_multi_index_attrs_df(attrs, alt_indexes)
        else:
            df_attrs, attr_ids = create_single_index_attrs_df(attrs)

        if (df_attrs.columns.size == 1) and (df_attrs.columns[0].lower() == 'value'):
            df_attrs.columns = ['value']
            assert len(attr_ids) == 1, f'Expected to have only one ID, instead got: {", ".join(attr_ids)}'
            df_attrs.columns.name = 'id'
            df_attrs = df_attrs.rename(columns={'value': attr_ids[0]})

        df_attrs = format_attribute_value_types(df_attrs, attr_to_field_schema)

        df_stacked_attrs = df_attrs.stack().reset_index().rename(columns={0: 'value'})
        df_stacked_attrs.columns = df_stacked_attrs.columns.str.lower()
        df_stacked_attrs['datapackage'] = datapackage_url
        df_stacked_attrs['id_type'] = datapackage_url_to_dict_id_type[datapackage_url]

        df_combined_attrs = df_combined_attrs.append(df_stacked_attrs)

    df_combined_attrs = df_combined_attrs.reset_index(drop=True)

    return df_combined_attrs


# Cell
def get_datapackage_url_to_attrs_md_str(single_site_data):
    attr_to_field_schema = construct_attr_to_field_schema(single_site_data)
    datapackage_url_to_alt_indexes = get_datapackage_url_to_alt_indexes(single_site_data)
    datapackage_url_to_attrs = get_datapackage_url_to_attributes(single_site_data)

    datapackage_url_to_md_str = {}

    for datapackage_url, attributes in datapackage_url_to_attrs.items():
        alt_indexes = datapackage_url_to_alt_indexes[datapackage_url]

        if len(alt_indexes) > 0:
            df_attrs, attr_ids = create_multi_index_attrs_df(attributes, alt_indexes)
        else:
            df_attrs, attr_ids = create_single_index_attrs_df(attributes)

        df_attrs = format_attribute_value_types(df_attrs, attr_to_field_schema)

        datapackage_url_to_md_str[datapackage_url] = (
            df_attrs.reset_index().astype(str).to_markdown(index=False, floatfmt='.2f')
        )

    return datapackage_url_to_md_str


# Cell
clean_dp_name = lambda dp_name: dp_name.replace('-', ' ').title()


def construct_dataset_md_str(dataset_metadata, dataset_attributes, dataset_page_url):
    title = clean_dp_name(dataset_metadata['datapackage_name'])
    dictionary_column_match = dataset_metadata['related_resources'][0]['dictionary_pk_field']
    dataset_column_match = dataset_metadata['related_resources'][0]['external_fk_field']

    if 'datapackage_description' in dataset_metadata.keys():
        description = dataset_metadata['datapackage_description']
    else:
        description = ''

    dataset_str = f"""##### <a href="{dataset_page_url}">{title}</a>

{description}

The \"{dictionary_column_match}\" dictionary field was matched to the \"{dataset_column_match}\" field in this dataset.

{dataset_attributes}\n"""

    return dataset_str


def single_site_data_to_datasets_md_str(single_site_data):
    datapackage_url_to_attrs_md_str = get_datapackage_url_to_attrs_md_str(single_site_data)
    dataset_url_to_md_str = {}

    for dataset_metadata in single_site_data['datasets'].values():
        dataset_url = dataset_metadata['datapackage_json_url']
        dataset_page_url = (
            f'https://osuked.github.io/Power-Station-Dictionary/datasets/{dataset_metadata["datapackage_name"]}'
        )
        dataset_attributes = datapackage_url_to_attrs_md_str[dataset_url]
        dataset_str = construct_dataset_md_str(dataset_metadata, dataset_attributes, dataset_page_url)

        dataset_url_to_md_str[dataset_url] = dataset_str

    datasets_md_str = '### Linked Datasets\n' + '\n<br><br>\n'.join(list(dataset_url_to_md_str.values()))

    return datasets_md_str


# Cell
def construct_downloads_md_str(object_id):
    file_md_table = pd.DataFrame(
        [
            {
                'File': 'Attributes',
                'Filepath': f'[{object_id}.csv](https://osuked.github.io/Power-Station-Dictionary/object_attrs/{object_id}.csv)',
            }
        ]
    ).to_markdown(index=False)

    downloads_str = f"""### Downloads\n

{file_md_table}\n"""

    return downloads_str


# Cell
construct_contributors_str = (
    lambda object_id: f"""### Contribute

We need your help! If you know of any data associated with this power plant which is currently missing then please add it using the relevant Google form which can be accessed with the buttons below.  If you are adding an ID from a linkage which is already known you need to only complete the *Add New Link* form, if the link type is not currently in the dictionary you will need to use the *Add New Link Type* form.\n\nThank You!

[Add New Link](https://docs.google.com/forms/d/e/1FAIpQLSc5jRsQ7NgiLLXbwo9PUdwTQyuqbRwThltG56-o6NVSe7E_nw/viewform?usp=pp_url&entry.251912331={object_id}){{ .md-button }}\n
[Add New Link Type](https://docs.google.com/forms/d/e/1FAIpQLSdQfLmfOR0Vw4Z7gDQAIhBbqIifd1RuSFPKmDQpROhOqjo7ew/viewform?usp=pp_url&entry.2141539628={object_id}){{ .md-button }}"""
)

# Cell
def extract_name_from_single_site_data(single_site_data):
    potential_names = [v['name'] for k, v in single_site_data['id_hierarchies'].items() if 'name' in v.keys()]

    if len(potential_names) > 0:
        name = potential_names[0]
        return name
    else:
        return None


def single_site_data_to_md_str(single_site_data, root_id, datapackage_json_fp):
    site_ids_md_str = single_site_data_to_ids_md_str(single_site_data, root_id, datapackage_json_fp)
    datasets_md_str = single_site_data_to_datasets_md_str(single_site_data)
    downloads_md_str = construct_downloads_md_str(root_id)
    contributors_str = construct_contributors_str(root_id)

    site_md_str = (
        site_ids_md_str
        + '\n\n<br>\n'
        + datasets_md_str
        + '\n\n<br>\n'
        + downloads_md_str
        + '\n\n<br>\n'
        + contributors_str
    )

    return site_md_str


def populate_and_save_template(template_fp, save_fp, render_kwargs):
    rendered_str = Template(open(template_fp).read()).render(**render_kwargs)

    with open(save_fp, 'w', encoding='utf-8') as f:
        try:
            f.write(rendered_str)
        except e as exc:
            raise exc

    return None


def clean_object_ids_to_names(object_ids_to_names):
    ## need to add a check that they're all unique
    object_names = sorted(object_ids_to_names.values())

    alpha_names = [name for name in object_names if name[0].isalpha()]
    numeric_names = [name for name in object_names if not name[0].isalpha()]

    object_names = alpha_names + numeric_names

    object_names_to_ids = {v: k for k, v in object_ids_to_names.items()}
    object_ids_to_names = {object_names_to_ids[v]: v for v in object_names}

    return object_ids_to_names


def get_object_ids_to_names(
    site_data: dict,
    datapackage_json_fp,
    use_name_as_suffix: bool = False,
    object_template_fp: str = 'templates/objects_page.md',
    docs_fp: str = 'docs',
):
    object_ids_to_names = {}
    df_all_sites_combined_attrs = pd.DataFrame()

    for dictionary_id, single_site_data in tqdm(site_data.items()):
        if 'attributes' in single_site_data.keys():
            attr_to_field_schema = construct_attr_to_field_schema(single_site_data)
            df_combined_attrs = extract_combined_attrs_df(single_site_data, attr_to_field_schema)
            df_combined_attrs.to_csv(f'{docs_fp}/object_attrs/{dictionary_id}.csv', index=False)

            df_combined_attrs = df_combined_attrs.assign(dictionary_id=dictionary_id)
            df_all_sites_combined_attrs = df_all_sites_combined_attrs.append(df_combined_attrs)

            name = extract_name_from_single_site_data(single_site_data)

            if name is not None:
                name = name.replace('/', '-').strip()
            else:
                name = dictionary_id

            object_ids_to_names[dictionary_id] = name

            if use_name_as_suffix == True:
                save_fp = f'{docs_fp}/objects/{name}.md'
            else:
                save_fp = f'{docs_fp}/objects/{dictionary_id}.md'

            render_kwargs = {
                'site_ids_md_string': single_site_data_to_md_str(single_site_data, dictionary_id, datapackage_json_fp)
            }
            populate_and_save_template(object_template_fp, save_fp, render_kwargs)

    object_ids_to_names = clean_object_ids_to_names(object_ids_to_names)
    df_all_sites_combined_attrs.to_csv(f'{docs_fp}/object_attrs/dictionary_attributes.csv', index=False)

    return object_ids_to_names


# Cell
def construct_object_docs(
    datapackage_fp,
    site_data: str = 'data/intermediate/site_data.json',
    mkdocs_template_fp: str = 'templates/mkdocs.yml',
    object_template_fp: str = 'templates/objects_page.md',
    save_fp: str = 'mkdocs.yml',
    docs_fp: str = 'docs',
):
    if isinstance(site_data, str):
        with open(site_data, 'r') as f:
            site_data = json.load(f)

    object_ids_to_names = get_object_ids_to_names(
        site_data, datapackage_fp, object_template_fp=object_template_fp, docs_fp=docs_fp
    )

    render_kwargs = {'object_ids_to_names': object_ids_to_names}
    populate_and_save_template(mkdocs_template_fp, save_fp, render_kwargs)
